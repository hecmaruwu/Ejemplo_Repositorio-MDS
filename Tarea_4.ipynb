{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hecmaruwu/Ejemplo_Repositorio-MDS/blob/main/Tarea_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Jfl4wVLW-4"
      },
      "source": [
        "# Tarea 4: Modelos basados en energía\n",
        "\n",
        "### MDS7203 Modelos Generativos Profundos\n",
        "\n",
        "**Nombre:**\n",
        "\n",
        "**Fecha de entrega:**\n",
        "\n",
        "En esta cuarta tarea se evaluarán los fundamentos de los modelos basados en energía, colocando énfasis en los modelos basados en score, los cuales, como sabemos, son esenciales para construir buenos modelos generativos condicionales mediante las técnicas de guidance. Además, el aprendizaje basado en score es relevante para formular modelos de difusión, tanto en su versión a tiempo discreto como en su versión continua.\n",
        "\n",
        "Algunas instrucciones generales:\n",
        "\n",
        "- Se pueden utilizar de manera libre herramientas como ChatGPT y Claude, entre otras.\n",
        "- Para la entrega, no es necesario un informe, este archivo es suficiente.\n",
        "- Se debe entregar el documento con todas las celdas ejecutadas.\n",
        "- Esta tarea puede ser resuelta en Google Colab o de manera local (no se utilizará GPU).\n",
        "- La tarea está compuesta por dos partes, una conceptual y otra práctica. Ambas partes valen lo mismo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjwDEwu6DKtr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from sklearn.datasets import make_swiss_roll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQScJQWYyWv"
      },
      "source": [
        "## Parte 1 (preguntas conceptuales)\n",
        "\n",
        "### Modelos basados en energía\n",
        "\n",
        "Un modelo basado en energía (EBM) clásico busca aprender una distribución de probabilidad desconocida $p_\\text{data}(x)$ parametrizando una función de densidad $p_\\theta(x)$ a partir de una red neuronal $E_\\theta:\\R^D\\to\\R$ mediante la expresión\n",
        "\n",
        "$$\n",
        "p_\\theta(x)=\\frac{\\exp\\left(-E_\\theta(x)\\right)}{Z_\\theta},\n",
        "\\quad\\text{donde}\\quad Z_\\theta=\\int_{\\R^D} \\exp\\left(-E_\\theta(x)\\right)\\text{d}x\n",
        "\\quad\\text{es la constante de normalización.}\n",
        "$$\n",
        "\n",
        "- ¿Por qué no es posible en general computar la log-verosimilitud $\\log p_\\theta(x)$? Si esta cantidad no es tratable, ¿cómo es posible entrenar un EBM mediante el criterio de máxima verosimilitud?\n",
        "> **Respuesta:** Primero que nada es necesario saber de que la función $p_\\thetha(x)$ se divide por la constante de normalización para que cumpla con el criterio de sumar 1 para ser una función de probabilidad, pero el problema es que no se conoce el valor de la constante y además no se puede computar porque la integral sobre Rd posee dimensiones altísimas (sobre todo en caso de imágenes), lo que hace costoso el proceso de cálculo.  \n",
        "Para lo anterior se busca entonces una alternativa, la cual es estimar por máxima verosimilitud, llegando a $$\n",
        "\\log p_\\theta(x) = -E_\\theta(x) - \\log Z_\\theta\n",
        "$$ , ojo, a pesar de eso no se puede estimar aún porque el log de la constante sigue siendo desconocida, aún al aplicar el gradiente de forma directa $$\n",
        "\\nabla_\\theta \\log p_\\theta(x) = -\\nabla_\\theta E_\\theta(x) - \\nabla_\\theta \\log Z_\\theta\n",
        "$$, pero si usamos el truco de reescribir esa función en base a las propiedades del gradiente.\n",
        "$$\n",
        "\\nabla_\\theta \\log Z_\\theta\n",
        "= \\frac{1}{Z_\\theta} \\nabla_\\theta Z_\\theta\n",
        "= \\frac{1}{Z_\\theta} \\nabla_\\theta \\int \\exp(-E_\\theta(x))\\, dx\n",
        "= - \\int p_\\theta(x) \\nabla_\\theta E_\\theta(x)\\, dx\n",
        "= - \\mathbb{E}_{x \\sim p_\\theta}[\\nabla_\\theta E_\\theta(x)]\n",
        "$$\n",
        "Entonces ahora podemos calcular el $$\\log Z_\\theta$$ como una esperanza, siendo la función objetivo:\n",
        "$$\n",
        "\\nabla_\\theta \\log p_\\theta(x) = -\\nabla_\\theta E_\\theta(x) + \\mathbb{E}_{x \\sim p_\\theta}[\\nabla_\\theta E_\\theta(x)]\n",
        "$$\n",
        "si nos fijamos ya no dependemos del z por lo que se pueden estimar los parámetors con una red neuronal\n",
        "\n",
        "\n",
        "- ¿Para qué se utiliza la dinámica de Langevin en este tipo de modelos? ¿Por qué es importante este algoritmo para el entrenamiento?\n",
        "> **Respuesta:**\n",
        "- ¿Por qué es lento entrenar directamente la función de energía $E_\\theta$ utilizando el enfoque de máxima verosimilitud?\n",
        "> **Respuesta:**\n",
        "\n",
        "### Modelos basados en score\n",
        "\n",
        "Una posible reparametrización de este tipo de modelos consiste en aprender la función de score $\\nabla_x \\log p_\\theta(x)$ entrenando una red neuronal $s_\\theta:\\R^D\\to\\R^D$ en vez de entrenar la función de energía $E_\\theta:\\R^D\\to\\R$ descrita anteriormente. Para esto, se suele usar como función objetivo la divergencia de Fisher:\n",
        "\n",
        "$$\n",
        "\\operatorname{D_F}\\left(p_{\\text{data}}(x)\\|p_\\theta(x)\\right):= \\mathbb{E}_{p_{\\text{data}}(x)}\\left[\\frac{1}{2}\\left\\|\\nabla_x\\log p_\\theta(x)-\\nabla_x\\log p_{\\text{data}}(x)\\right\\|^2\\right]\n",
        "$$\n",
        "\n",
        "Si bien esta cantidad no es directamente computable (ya que no se conoce el score real $\\nabla_x\\log p_{\\text{data}}(x)$), en clases se demostró que la divergencia de Fisher toma la siguiente forma tratable para su optimización:\n",
        "\n",
        "$$\n",
        "\\operatorname{D_F}\\left(p_{\\text{data}}(x)\\|p_\\theta(x)\\right) = \\mathbb{E}_{p_{\\text{data}}(x)}\\left[\\frac{1}{2}\\left\\|s_\\theta(x)\\right\\|^2 + \\operatorname{Div}\\left( s_\\theta(x)\\right)\\right] + \\operatorname{constante}\n",
        "$$\n",
        "\n",
        "Al entrenamiento de un modelo basado en score utilizando esta función objetivo se le suele llamar score matching (SM).\n",
        "\n",
        "- ¿Cuál es la motivación para aprender el score $\\nabla_x \\log p_\\theta(x)$ en vez de la función de energía $E_\\theta(x)$ asociada a $p_\\theta(x)$? Relaciónelo con la dinámica de Lanvegin.\n",
        "> **Respuesta:**\n",
        "- ¿Cuál es la principal limitación del enfoque SM que motiva a usar técnicas alternativas como denoising score matching (DSM)?\n",
        "> **Respuesta:**\n",
        "\n",
        "### Guidance\n",
        "\n",
        "Una de las propiedades más importantes de los modelos basados en score es que permiten aplicar la técnica de guidance para realizar generación condicional. Como vimos en clases, esta técnica es esencial en los modelos de difusión para poder obtener buenos resultados que se ajusten al prompt dado como factor condicionante.\n",
        "\n",
        "- ¿Qué elemento adicional necesita la técnica de classifier guidance para realizar generación condicional a partir de un modelo de score entrenado de forma incondicional? ¿Cuál es la principal limitación de este método?\n",
        "> **Respuesta:**\n",
        "- La técnica de classifier-free guidance es una modificación de la técnica de classifier guidance que permite realizar generación condicional pero ahora utilizando un modelo de score entrenado de forma condicional. ¿Cuáles son las ventajas de usar este enfoque en vez de utilizar directamente el modelo de score condicional ya entrenado? ¿Por qué ya no es necesario entrenar un clasificador con este enfoque?\n",
        "> **Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46N8phMGYyWw"
      },
      "source": [
        "## Parte 2 (implementación)\n",
        "\n",
        "En esta segunda parte se pide implementar la técnica de score matching original (i.e., la que optimiza la cantidad $\\operatorname{D_F}\\left(p_{\\text{data}}(x)\\|p_\\theta(x)\\right) = \\mathbb{E}_{p_{\\text{data}}(x)}\\left[\\frac{1}{2}\\left\\|s_\\theta(x)\\right\\|^2 + \\operatorname{Div}\\left( s_\\theta(x)\\right)\\right] + \\operatorname{constante}$). Para esto, se trabajará con el mismo dataset de juguete que se utiliza en clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrHoCjAAYyWx"
      },
      "outputs": [],
      "source": [
        "def get_batch(batch_size=100, noise=0.1):\n",
        "    x, _ = make_swiss_roll(batch_size, noise=noise)\n",
        "    x = x[:, [0, 2]]\n",
        "    x = (x - x.mean()) / x.std()\n",
        "    return torch.tensor(x).float()\n",
        "\n",
        "# Ejemplo:\n",
        "samples = get_batch(batch_size=1000)\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.scatter(samples[:, 0], samples[:, 1], s=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yecGHh9pYyWx"
      },
      "source": [
        "### Clase `SM`\n",
        "\n",
        "La siguiente clase se utilizará entrenar un modelo basado en score utilizando el enfoque DSM (ya implementado) o el enfoque SM (se debe implementar). Para esto, el parámetro `dsm` en el método `train_model` permite indicar qué enfoque se utilizará para el entrenamiento.\n",
        "\n",
        "- Complete el código del método `train_model` para obtener `loss` mediante el método de SM.\n",
        "- Implemente el método `generate_samples` que genera nuevas muestras utilizando la dinámica de Langevin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db4J7m3KYyWy"
      },
      "outputs": [],
      "source": [
        "class SM:\n",
        "\n",
        "    @staticmethod\n",
        "    def train_model(net, optimizer, dsm, n_iters):\n",
        "\n",
        "        for _ in tqdm.trange(n_iters):\n",
        "\n",
        "            x = get_batch()\n",
        "\n",
        "            # ---------------- Cálculo de loss ----------------\n",
        "\n",
        "            # Denoising score matching.\n",
        "            if dsm:\n",
        "                sigma = 0.1\n",
        "                x_bar = x + sigma * torch.randn_like(x)\n",
        "                score = net(x_bar)\n",
        "                inner = (x - x_bar) / sigma**2 - score\n",
        "                loss =  1/2 * (torch.linalg.norm(inner, dim=-1) ** 2).mean()\n",
        "\n",
        "            # Score matching.\n",
        "            else:\n",
        "                ...\n",
        "\n",
        "            # ---------------- Optimización ----------------\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_samples(net, n_samples, step_size=0.001, n_steps=1000):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ...\n",
        "            return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Uh-WsWKYyWz"
      },
      "source": [
        "### Red neuronal\n",
        "\n",
        "Dado que se está trabajando con un dataset de juguete, es suficiente considerar una red fully connected para aprender la función de score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cW2X0m9YyWz"
      },
      "outputs": [],
      "source": [
        "class ScoreNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, data_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(data_dim, 64), nn.LogSigmoid(),\n",
        "            nn.Linear(64, 64), nn.LogSigmoid(),\n",
        "            nn.Linear(64, 64), nn.LogSigmoid(),\n",
        "            nn.Linear(64, data_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOssamnaYyW0"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "A continuación se entrenará un modelo de score utilizando ambos enfoques. El objetivo será comparar los tiempos de entrenamiento y la calidad de las muestras generadas utilizando ambos métodos.\n",
        "\n",
        "#### Entrenamiento para DSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKlnnxBpYyW0"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento:\n",
        "dsm_net = ScoreNetwork(data_dim=2)\n",
        "dsm_optimizer = optim.Adam(dsm_net.parameters(), lr=3e-4)\n",
        "SM.train_model(dsm_net, dsm_optimizer,dsm=True, n_iters=30000)\n",
        "\n",
        "# Generación de muestras:\n",
        "dsm_samples = SM.generate_samples(dsm_net, n_samples=1000)\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.scatter(dsm_samples[:, 0], dsm_samples[:, 1], s=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbHa6RfcYyW0"
      },
      "source": [
        "#### Entrenamiento para SM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMLpZ9OGYyW0"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento:\n",
        "sm_net = ScoreNetwork(data_dim=2)\n",
        "sm_optimizer = optim.Adam(sm_net.parameters(), lr=3e-4)\n",
        "SM.train_model(sm_net, sm_optimizer, dsm=False, n_iters=30000)\n",
        "\n",
        "# Generación de muestras:\n",
        "sm_samples = SM.generate_samples(sm_net, n_samples=1000)\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.scatter(sm_samples[:, 0], sm_samples[:, 1], s=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORc0KakJYyW1"
      },
      "source": [
        "- ¿Cuál de los dos entrenamientos toma más tiempo? ¿A qué se debe esto?\n",
        "> **Respuesta:**\n",
        "- ¿Cuál de los dos enfoques genera muestras de mejor calidad? ¿A qué se debe esto?\n",
        "> **Respuesta:**\n",
        "- ¿Cuál es la limitación del enfoque de DSM que motiva a usar DSM con varios niveles de ruido?\n",
        "> **Respuesta:**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}